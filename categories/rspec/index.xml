<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Rspec on Artsy Engineering</title>
    <link>https://hizkifw.github.io/artsy.github.io-hugo/categories/rspec/</link>
    <description>Recent content in Rspec on Artsy Engineering</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 24 Sep 2015 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://hizkifw.github.io/artsy.github.io-hugo/categories/rspec/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Splitting up a large test suite</title>
      <link>https://hizkifw.github.io/artsy.github.io-hugo/2015/09/24/splitting-up-a-large-test-suite/</link>
      <pubDate>Thu, 24 Sep 2015 00:00:00 +0000</pubDate>
      
      <guid>https://hizkifw.github.io/artsy.github.io-hugo/2015/09/24/splitting-up-a-large-test-suite/</guid>
      <description>&lt;p&gt;A while back, we wrote about &lt;a href=&#34;https://hizkifw.github.io/artsy.github.io-hugo/blog/2012/10/09/how-to-run-rspec-test-suites-in-parallel-with-jenkins-ci-build-flow/&#34;&gt;How to Run RSpec Test Suites in Parallel with Jenkins CI Build Flow&lt;/a&gt;. A version of that still handles our largest test suite, but over time the initial division of specs became unbalanced. We ended up with some tasks that took twice as long as others. Even worse, in an attempt to rebalance task times, we ended up with awkward file patterns like &lt;code&gt;&#39;spec/api/**/[a-m]*_spec.rb&#39;&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;To keep our parallel spec tasks approximately equal in size and to support arbitrary concurrency, we&amp;rsquo;ve added a new &lt;code&gt;spec:sliced&lt;/code&gt; task:&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Continuous integration for service-oriented architectures</title>
      <link>https://hizkifw.github.io/artsy.github.io-hugo/2014/05/12/continuous-integration-for-service-oriented-architectures/</link>
      <pubDate>Mon, 12 May 2014 00:00:00 +0000</pubDate>
      
      <guid>https://hizkifw.github.io/artsy.github.io-hugo/2014/05/12/continuous-integration-for-service-oriented-architectures/</guid>
      <description>&lt;p&gt;Whatever you have against monolithic architectures, at least they&amp;rsquo;re easy to test. And when those tests succeed, you can be reasonably confident the live app will work the same way.&lt;/p&gt;

&lt;p&gt;Artsy began as one such monolithic app, but we&amp;rsquo;ve been refactoring into an ecosystem of related APIs and sites. Today, when you search for &lt;a href=&#34;https://artsy.net/gene/cultural-commentary&#34;&gt;&amp;ldquo;cultural commentary&amp;rdquo;&lt;/a&gt; or visit &lt;a href=&#34;https://artsy.net/artist/robert-longo&#34;&gt;Robert Longo&lt;/a&gt; on &lt;a href=&#34;https://artsy.net&#34;&gt;artsy.net&lt;/a&gt;, the page is rendered by a web app, sources data from an API, retrieves recommendations from a separate service, tracks trends in another, and records analytics in yet another.&lt;/p&gt;

&lt;p&gt;This was a boost for developer productivity and scaling, but eviscerated the value of our tests. We repeatedly encountered bugs that were failings of &lt;em&gt;the interaction between codebases&lt;/em&gt; rather than failings of individual ones. Test libraries and tools typically concern themselves with one isolated app. When you have services that consume services that consume services, those isolated tests (with their stubs of everything else) don&amp;rsquo;t necessarily reflect production&amp;rsquo;s reality.&lt;/p&gt;

&lt;p&gt;So how should we develop our small, focused apps (or &lt;a href=&#34;http://en.wikipedia.org/wiki/Service-oriented_architecture&#34;&gt;service-oriented architecture&lt;/a&gt;, or &lt;a href=&#34;http://martinfowler.com/articles/microservices.html&#34;&gt;microservices&lt;/a&gt;&amp;hellip;) with confidence? We set out to build a dedicated acceptance test suite that would run tests across multiple services, configuring and integrating them in a way that closely matches the production environment.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Isolating Spurious and Nondeterministic Tests</title>
      <link>https://hizkifw.github.io/artsy.github.io-hugo/2014/01/30/isolating-spurious-and-nondeterministic-tests/</link>
      <pubDate>Thu, 30 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>https://hizkifw.github.io/artsy.github.io-hugo/2014/01/30/isolating-spurious-and-nondeterministic-tests/</guid>
      <description>&lt;p&gt;Testing is a critical part of our workflow at &lt;a href=&#34;https://artsy.net&#34;&gt;Artsy&lt;/a&gt;. It gives us confidence to make regular, aggressive enhancements. But anyone who has worked with a large, complex test suite has struggled with occasional failures that are difficult to reproduce or fix.&lt;/p&gt;

&lt;p&gt;These failures might be due to slight timing differences or lack of proper isolation between tests. Integration tests are particularly thorny, since problems can originate not only in application code, but in the browser, testing tools (e.g., &lt;a href=&#34;http://docs.seleniumhq.org/&#34;&gt;Selenium&lt;/a&gt;), database, network, or external APIs and dependencies.&lt;/p&gt;

&lt;h2 id=&#34;the-quarantine&#34;&gt;The Quarantine&lt;/h2&gt;

&lt;p&gt;We&amp;rsquo;ve been &lt;a href=&#34;http://artsy.github.io/blog/2012/05/15/how-to-organize-over-3000-rspec-specs-and-retry-test-failures/&#34;&gt;automatically retrying failed tests&lt;/a&gt;, with some success. However, these problems tend to get worse. (If you have 10 tests that each have a 1% chance of failing, roughly 1 in 10 builds will fail. If you have 50, 4 in 10 builds will fail.)&lt;/p&gt;

&lt;p&gt;Martin Fowler offers the most compelling thoughts on this topic in &lt;a href=&#34;http://martinfowler.com/articles/nonDeterminism.html&#34;&gt;Eradicating Non-Determinism in Tests&lt;/a&gt;. (Read it, really.) He suggests quarantining problematic tests in a separate suite, so they don&amp;rsquo;t block the build pipeline.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>How to Run RSpec Test Suites in Parallel with JenkinsCI Build Flow</title>
      <link>https://hizkifw.github.io/artsy.github.io-hugo/2012/10/09/how-to-run-rspec-test-suites-in-parallel-with-jenkins-ci-build-flow/</link>
      <pubDate>Tue, 09 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>https://hizkifw.github.io/artsy.github.io-hugo/2012/10/09/how-to-run-rspec-test-suites-in-parallel-with-jenkins-ci-build-flow/</guid>
      <description>&lt;p&gt;We now have over 4700 RSpec examples in one of our projects. They are stable, using the techniques described in an &lt;a href=&#34;https://hizkifw.github.io/artsy.github.io-hugo/blog/2012/02/03/reliably-testing-asynchronous-ui-w-slash-rspec-and-capybara/&#34;&gt;earlier post&lt;/a&gt; and organized in &lt;a href=&#34;https://hizkifw.github.io/artsy.github.io-hugo/blog/2012/05/15/how-to-organize-over-3000-rspec-specs-and-retry-test-failures/&#34;&gt;suites&lt;/a&gt;. But they now take almost 3 hours to run, which is clearly unacceptable.&lt;/p&gt;

&lt;p&gt;To solve this, we have parallelized parts of the process with existing tools, and can turn a build around in just under an hour. This post will dive into our &lt;a href=&#34;http://jenkins-ci.org/&#34;&gt;Jenkins&lt;/a&gt; build flow setup.&lt;/p&gt;

&lt;p&gt;To keep things simple, we&amp;rsquo;re going to only build the &lt;code&gt;master&lt;/code&gt; branch. When a change is committed on &lt;code&gt;master&lt;/code&gt; we&amp;rsquo;re going to push &lt;code&gt;master&lt;/code&gt; to a &lt;code&gt;master-ci&lt;/code&gt; branch and trigger a distributed build on &lt;code&gt;master-ci&lt;/code&gt;. Once all the parts have finished, we&amp;rsquo;ll complete the build by pushing &lt;code&gt;master-ci&lt;/code&gt; to &lt;code&gt;master-succeeded&lt;/code&gt; and notify the dev team of success or failure.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s a diagram of what&amp;rsquo;s going on.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://hizkifw.github.io/artsy.github.io-hugo/images/2012-10-09-how-to-run-rspec-test-suites-in-parallel-with-jenkins-ci-build-flow/master-ci.png&#34;&gt;&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Testing with Delayed Jobs</title>
      <link>https://hizkifw.github.io/artsy.github.io-hugo/2012/08/16/testing-with-delayed-jobs/</link>
      <pubDate>Thu, 16 Aug 2012 00:00:00 +0000</pubDate>
      
      <guid>https://hizkifw.github.io/artsy.github.io-hugo/2012/08/16/testing-with-delayed-jobs/</guid>
      <description>&lt;p&gt;A mean bug made it into our production environment. It wasn&amp;rsquo;t caught by our extensive test suite and caused thousands of emails to be sent to a handful of people. The root cause was an unfortunate combination of &lt;a href=&#34;https://github.com/plataformatec/devise&#34;&gt;Devise&lt;/a&gt;, &lt;a href=&#34;https://github.com/collectiveidea/delayed_job&#34;&gt;DelayedJob&lt;/a&gt; and, of course, our own code. It was an easy fix, but nobody ever wants this to happen again.&lt;/p&gt;

&lt;p&gt;tl;dr DelayedJob says it&amp;rsquo;s possible to set &lt;code&gt;Delayed::Worker.delay_jobs = false&lt;/code&gt; for your tests. Don&amp;rsquo;t do it.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>How to Organize Over 3000 RSpec Specs and Retry Test Failures</title>
      <link>https://hizkifw.github.io/artsy.github.io-hugo/2012/05/15/how-to-organize-over-3000-rspec-specs-and-retry-test-failures/</link>
      <pubDate>Tue, 15 May 2012 00:00:00 +0000</pubDate>
      
      <guid>https://hizkifw.github.io/artsy.github.io-hugo/2012/05/15/how-to-organize-over-3000-rspec-specs-and-retry-test-failures/</guid>
      <description>&lt;p&gt;Having over three thousand RSpec tests in a single project has become difficult to manage. We chose to organize these into suites, somewhat mimicking our directory structure. And while we succeeded at making our Capybara integration tests more reliable (see &lt;a href=&#34;https://hizkifw.github.io/artsy.github.io-hugo/blog/2012/02/03/reliably-testing-asynchronous-ui-w-slash-rspec-and-capybara/&#34;&gt;Reliably Testing Asynchronous UI with RSpec and Capybara&lt;/a&gt;), they continue relying on finicky timeouts. To avoid too many false positives we&amp;rsquo;ve put together a system to retry failed tests. We know that a spec that fails twice in a row is definitely not a fluke!&lt;/p&gt;

&lt;p&gt;Create a new Rake file in &lt;code&gt;lib/tasks/test_suites.rake&lt;/code&gt; and declare an array of test suites.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Reliably Testing Asynchronous UI w/ RSpec and Capybara</title>
      <link>https://hizkifw.github.io/artsy.github.io-hugo/2012/02/03/reliably-testing-asynchronous-ui-w-slash-rspec-and-capybara/</link>
      <pubDate>Fri, 03 Feb 2012 00:00:00 +0000</pubDate>
      
      <guid>https://hizkifw.github.io/artsy.github.io-hugo/2012/02/03/reliably-testing-asynchronous-ui-w-slash-rspec-and-capybara/</guid>
      <description>&lt;p&gt;tl;dr - You can write 632 rock solid UI tests with Capybara and RSpec, too.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;Miami Weather in NYC&#34; alt=&#34;/images/2012-02-03-reliably-testing-asynchronous-ui-w-slash-rspec-and-capybara/jenkins-ci.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;We have exactly 231 integration tests and 401 view tests out of a total of 3086 in our core application today. This adds up to 632 tests that exercise UI. The vast majority use &lt;a href=&#34;http://rspec.info/&#34;&gt;RSpec&lt;/a&gt; with &lt;a href=&#34;https://github.com/jnicklas/capybara&#34;&gt;Capybara&lt;/a&gt; and &lt;a href=&#34;http://seleniumhq.org/&#34;&gt;Selenium&lt;/a&gt;. This means that every time the suite runs we set up real data in a local MongoDB and use a real browser to hit a fully running local application, 632 times. The suite currently takes 45 minutes to run headless on a slow Linode, UI tests taking more than half the time.&lt;/p&gt;

&lt;p&gt;While the site is in private beta, you can get a glimpse of the complexity of the UI from the &lt;a href=&#34;http://artsy.net&#34;&gt;splash page&lt;/a&gt;. It&amp;rsquo;s a rich client-side Javascript application that talks to an API. You can open your browser&amp;rsquo;s developer tools and watch a combination of API calls and many asynchronous events.&lt;/p&gt;

&lt;p&gt;Keeping the UI tests reliable is notoriously difficult. For the longest time we felt depressed under the Pacific Northwest -like weather of our Jenkins CI and blamed every possible combination of code and infrastructure for the many intermittent failures. We&amp;rsquo;ve gone on sprees of marking many such tests &amp;ldquo;pending&amp;rdquo; too.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ve learned a lot and stabilized our test suite. This is how we do UI testing.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>